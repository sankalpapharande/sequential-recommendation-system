{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lgrtxqOZ35vN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting recbole\n",
      "  Downloading recbole-1.0.1-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard>=2.5.0\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting scipy==1.6.0\n",
      "  Downloading scipy-1.6.0-cp39-cp39-macosx_10_9_x86_64.whl (30.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.9 MB 4.6 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.7.0 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from recbole) (1.11.0)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from recbole) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from recbole) (1.21.5)\n",
      "Collecting colorama==0.4.4\n",
      "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting scikit-learn>=0.23.2\n",
      "  Using cached scikit_learn-1.0.2-cp39-cp39-macosx_10_13_x86_64.whl (8.0 MB)\n",
      "Collecting pyyaml>=5.1.0\n",
      "  Downloading PyYAML-6.0-cp39-cp39-macosx_10_9_x86_64.whl (197 kB)\n",
      "\u001b[K     |████████████████████████████████| 197 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.0.5 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from recbole) (1.4.2)\n",
      "Collecting colorlog==4.7.2\n",
      "  Downloading colorlog-4.7.2-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from pandas>=1.0.5->recbole) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from pandas>=1.0.5->recbole) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.5->recbole) (1.16.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from scikit-learn>=0.23.2->recbole) (1.1.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorboard>=2.5.0->recbole) (2.27.1)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp39-cp39-macosx_10_10_x86_64.whl (4.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.6.0\n",
      "  Downloading protobuf-3.20.1-cp39-cp39-macosx_10_9_x86_64.whl (962 kB)\n",
      "\u001b[K     |████████████████████████████████| 962 kB 8.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.1.1-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 6.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorboard>=2.5.0->recbole) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from tensorboard>=2.5.0->recbole) (61.2.0)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->recbole) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->recbole) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->recbole) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->recbole) (3.3)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: typing_extensions in /Users/sankalpapharande/opt/anaconda3/envs/pytorch_env/lib/python3.9/site-packages (from torch>=1.7.0->recbole) (4.1.1)\n",
      "Installing collected packages: pyasn1, zipp, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, threadpoolctl, tensorboard-plugin-wit, tensorboard-data-server, scipy, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard, scikit-learn, pyyaml, colorlog, colorama, recbole\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.8.0\n",
      "    Uninstalling scipy-1.8.0:\n",
      "      Successfully uninstalled scipy-1.8.0\n",
      "Successfully installed absl-py-1.0.0 cachetools-5.0.0 colorama-0.4.4 colorlog-4.7.2 google-auth-2.6.6 google-auth-oauthlib-0.4.6 grpcio-1.44.0 importlib-metadata-4.11.3 markdown-3.3.6 oauthlib-3.2.0 protobuf-3.20.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyyaml-6.0 recbole-1.0.1 requests-oauthlib-1.3.1 rsa-4.8 scikit-learn-1.0.2 scipy-1.6.0 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 threadpoolctl-3.1.0 werkzeug-2.1.1 zipp-3.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install recbole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pfOzpdBdOIKK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.chdir('/content/drive/MyDrive/hnm')\n",
    "DATA_PATH = Path.cwd() / 'data'\n",
    "RAW = DATA_PATH / 'raw'\n",
    "PROCESSED = DATA_PATH / 'processed'\n",
    "SUBMISSION = DATA_PATH / 'submission'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.sequential_recommender import GRU4Rec\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KFn0LnVbn8uU"
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/drive/MyDrive/hnm/gru4rec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hlm4T8E-TCla",
    "outputId": "cc5ed6b2-ff48-4e28-f957-b71d0b4abb48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29 Mar 12:23    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /content/drive/MyDrive/hnm/data/processed/recbox_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "neg_sampling = None\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [9, 0, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
      "repeatable = True\n",
      "metrics = ['MAP']\n",
      "topk = [12]\n",
      "valid_metric = MAP@12\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [40,inf)\n",
      "item_inter_num_interval = [40,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /content/drive/MyDrive/hnm/data/processed/recbox_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "neg_sampling = None\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [9, 0, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
      "repeatable = True\n",
      "metrics = ['MAP']\n",
      "topk = [12]\n",
      "valid_metric = MAP@12\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [40,inf)\n",
      "item_inter_num_interval = [40,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = /content/drive/MyDrive/hnm/data/processed/recbox_data\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 50\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "neg_sampling = None\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [9, 0, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}\n",
      "repeatable = True\n",
      "metrics = ['MAP']\n",
      "topk = [12]\n",
      "valid_metric = MAP@12\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'timestamp']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [40,inf)\n",
      "item_inter_num_interval = [40,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "wandb_project = recbole\n",
      "require_pow = False\n",
      "embedding_size = 64\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "dropout_prob = 0.3\n",
      "loss_type = CE\n",
      "MODEL_TYPE = ModelType.SEQUENTIAL\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "device = cuda\n",
      "train_neg_sample_args = {'strategy': 'none'}\n",
      "eval_neg_sample_args = {'strategy': 'full', 'distribution': 'uniform'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameter_dict = {\n",
    "    'data_path': PROCESSED,\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'TIME_FIELD': 'timestamp',\n",
    "    'user_inter_num_interval': \"[40,inf)\",\n",
    "    'item_inter_num_interval': \"[40,inf)\",\n",
    "    'load_col': {'inter': ['user_id', 'item_id', 'timestamp']},\n",
    "    'neg_sampling': None,\n",
    "    'epochs': 50,\n",
    "    'metrics': ['MAP'],\n",
    "    'valid_metric': 'MAP@12',\n",
    "    'topk': [12],\n",
    "    'eval_args': {\n",
    "        'split': {'RS': [9, 0, 1]},\n",
    "        'group_by': 'user',\n",
    "        'order': 'TO',\n",
    "        'mode': 'full'}\n",
    "}\n",
    "\n",
    "config = Config(model='GRU4Rec', dataset='recbox_data', config_dict=parameter_dict)\n",
    "\n",
    "# init random seed\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(c_handler)\n",
    "\n",
    "# write config info into log\n",
    "logger.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CSuDOJ7bTXK3",
    "outputId": "f8febeb2-f4ae-4694-9130-cd2c3c8754b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29 Mar 12:28    INFO  recbox_data\n",
      "The number of users: 223128\n",
      "Average actions of users: 85.38935673405729\n",
      "The number of items: 51558\n",
      "Average actions of items: 369.5457648815874\n",
      "The number of inters: 19052671\n",
      "The sparsity of the dataset: 99.8343826873777%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "recbox_data\n",
      "The number of users: 223128\n",
      "Average actions of users: 85.38935673405729\n",
      "The number of items: 51558\n",
      "Average actions of items: 369.5457648815874\n",
      "The number of inters: 19052671\n",
      "The sparsity of the dataset: 99.8343826873777%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n",
      "recbox_data\n",
      "The number of users: 223128\n",
      "Average actions of users: 85.38935673405729\n",
      "The number of items: 51558\n",
      "Average actions of items: 369.5457648815874\n",
      "The number of inters: 19052671\n",
      "The sparsity of the dataset: 99.8343826873777%\n",
      "Remain Fields: ['user_id', 'item_id', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVvz_7EYTXdi",
    "outputId": "c8e7a3f7-2b97-495e-d9a6-f7ee17853ffa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29 Mar 12:33    INFO  [Training]: train_batch_size = [2048] negative sampling: [None]\n",
      "[Training]: train_batch_size = [2048] negative sampling: [None]\n",
      "[Training]: train_batch_size = [2048] negative sampling: [None]\n",
      "29 Mar 12:33    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [9, 0, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [9, 0, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n",
      "[Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [9, 0, 1]}, 'group_by': 'user', 'order': 'TO', 'mode': 'full'}]\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = data_preparation(config, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eC07_j-mPmF8",
    "outputId": "5246b0e4-205d-4ddc-a650-9b35446375e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29 Mar 12:34    INFO  GRU4Rec(\n",
      "  (item_embedding): Embedding(51558, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 3381696\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(51558, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 3381696\n",
      "GRU4Rec(\n",
      "  (item_embedding): Embedding(51558, 64, padding_idx=0)\n",
      "  (emb_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (gru_layers): GRU(64, 128, bias=False, batch_first=True)\n",
      "  (dense): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (loss_fct): CrossEntropyLoss()\n",
      ")\n",
      "Trainable parameters: 3381696\n"
     ]
    }
   ],
   "source": [
    "model = GRU4Rec(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hgPIvcfqq7Sr"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exVIgfDtCxMW",
    "outputId": "76971e7b-418d-4b7d-e42d-b2f61eb6cf5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train     0: 100%|█████████████████████| 8323/8323 [05:39<00:00, 24.53it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 12:40    INFO  epoch 0 training [time: 339.31s, train loss: 71936.9081]\n",
      "epoch 0 training [time: 339.31s, train loss: 71936.9081]\n",
      "epoch 0 training [time: 339.31s, train loss: 71936.9081]\n",
      "29 Mar 12:40    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train     1: 100%|█████████████████████| 8323/8323 [05:37<00:00, 24.68it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 12:46    INFO  epoch 1 training [time: 337.19s, train loss: 66461.1367]\n",
      "epoch 1 training [time: 337.19s, train loss: 66461.1367]\n",
      "epoch 1 training [time: 337.19s, train loss: 66461.1367]\n",
      "29 Mar 12:46    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train     2: 100%|█████████████████████| 8323/8323 [05:36<00:00, 24.70it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 12:52    INFO  epoch 2 training [time: 336.94s, train loss: 64798.1579]\n",
      "epoch 2 training [time: 336.94s, train loss: 64798.1579]\n",
      "epoch 2 training [time: 336.94s, train loss: 64798.1579]\n",
      "29 Mar 12:52    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train     3: 100%|█████████████████████| 8323/8323 [05:35<00:00, 24.84it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 12:57    INFO  epoch 3 training [time: 335.14s, train loss: 63887.0065]\n",
      "epoch 3 training [time: 335.14s, train loss: 63887.0065]\n",
      "epoch 3 training [time: 335.14s, train loss: 63887.0065]\n",
      "29 Mar 12:57    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train     4: 100%|█████████████████████| 8323/8323 [05:36<00:00, 24.71it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 13:03    INFO  epoch 4 training [time: 336.79s, train loss: 63305.2948]\n",
      "epoch 4 training [time: 336.79s, train loss: 63305.2948]\n",
      "epoch 4 training [time: 336.79s, train loss: 63305.2948]\n",
      "29 Mar 13:03    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train     5: 100%|█████████████████████| 8323/8323 [05:34<00:00, 24.88it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 13:08    INFO  epoch 5 training [time: 334.53s, train loss: 62920.9997]\n",
      "epoch 5 training [time: 334.53s, train loss: 62920.9997]\n",
      "epoch 5 training [time: 334.53s, train loss: 62920.9997]\n",
      "29 Mar 13:08    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train     6: 100%|█████████████████████| 8323/8323 [05:34<00:00, 24.85it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 13:14    INFO  epoch 6 training [time: 334.97s, train loss: 62650.8588]\n",
      "epoch 6 training [time: 334.97s, train loss: 62650.8588]\n",
      "epoch 6 training [time: 334.97s, train loss: 62650.8588]\n",
      "29 Mar 13:14    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train     7: 100%|█████████████████████| 8323/8323 [05:30<00:00, 25.22it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 13:20    INFO  epoch 7 training [time: 330.03s, train loss: 62453.8889]\n",
      "epoch 7 training [time: 330.03s, train loss: 62453.8889]\n",
      "epoch 7 training [time: 330.03s, train loss: 62453.8889]\n",
      "29 Mar 13:20    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train     8: 100%|█████████████████████| 8323/8323 [05:32<00:00, 25.03it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 13:25    INFO  epoch 8 training [time: 332.57s, train loss: 62299.6933]\n",
      "epoch 8 training [time: 332.57s, train loss: 62299.6933]\n",
      "epoch 8 training [time: 332.57s, train loss: 62299.6933]\n",
      "29 Mar 13:25    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train     9: 100%|█████████████████████| 8323/8323 [05:37<00:00, 24.62it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 13:31    INFO  epoch 9 training [time: 338.01s, train loss: 62172.5099]\n",
      "epoch 9 training [time: 338.01s, train loss: 62172.5099]\n",
      "epoch 9 training [time: 338.01s, train loss: 62172.5099]\n",
      "29 Mar 13:31    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    10: 100%|█████████████████████| 8323/8323 [05:39<00:00, 24.48it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 13:36    INFO  epoch 10 training [time: 339.96s, train loss: 62069.5242]\n",
      "epoch 10 training [time: 339.96s, train loss: 62069.5242]\n",
      "epoch 10 training [time: 339.96s, train loss: 62069.5242]\n",
      "29 Mar 13:36    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    11: 100%|█████████████████████| 8323/8323 [05:39<00:00, 24.54it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 13:42    INFO  epoch 11 training [time: 339.11s, train loss: 61979.8297]\n",
      "epoch 11 training [time: 339.11s, train loss: 61979.8297]\n",
      "epoch 11 training [time: 339.11s, train loss: 61979.8297]\n",
      "29 Mar 13:42    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    12: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.33it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 13:48    INFO  epoch 12 training [time: 342.05s, train loss: 61904.8058]\n",
      "epoch 12 training [time: 342.05s, train loss: 61904.8058]\n",
      "epoch 12 training [time: 342.05s, train loss: 61904.8058]\n",
      "29 Mar 13:48    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    13: 100%|█████████████████████| 8323/8323 [05:45<00:00, 24.07it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 13:53    INFO  epoch 13 training [time: 345.85s, train loss: 61841.2200]\n",
      "epoch 13 training [time: 345.85s, train loss: 61841.2200]\n",
      "epoch 13 training [time: 345.85s, train loss: 61841.2200]\n",
      "29 Mar 13:53    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    14: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.27it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 13:59    INFO  epoch 14 training [time: 342.91s, train loss: 61784.5272]\n",
      "epoch 14 training [time: 342.91s, train loss: 61784.5272]\n",
      "epoch 14 training [time: 342.91s, train loss: 61784.5272]\n",
      "29 Mar 13:59    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    15: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.28it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 14:05    INFO  epoch 15 training [time: 342.81s, train loss: 61734.6203]\n",
      "epoch 15 training [time: 342.81s, train loss: 61734.6203]\n",
      "epoch 15 training [time: 342.81s, train loss: 61734.6203]\n",
      "29 Mar 14:05    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    16: 100%|█████████████████████| 8323/8323 [05:43<00:00, 24.24it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 14:11    INFO  epoch 16 training [time: 343.35s, train loss: 61690.5179]\n",
      "epoch 16 training [time: 343.35s, train loss: 61690.5179]\n",
      "epoch 16 training [time: 343.35s, train loss: 61690.5179]\n",
      "29 Mar 14:11    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    17: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.27it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 14:16    INFO  epoch 17 training [time: 342.99s, train loss: 61650.3699]\n",
      "epoch 17 training [time: 342.99s, train loss: 61650.3699]\n",
      "epoch 17 training [time: 342.99s, train loss: 61650.3699]\n",
      "29 Mar 14:16    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    18: 100%|█████████████████████| 8323/8323 [05:44<00:00, 24.17it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 14:22    INFO  epoch 18 training [time: 344.39s, train loss: 61617.3958]\n",
      "epoch 18 training [time: 344.39s, train loss: 61617.3958]\n",
      "epoch 18 training [time: 344.39s, train loss: 61617.3958]\n",
      "29 Mar 14:22    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    19: 100%|█████████████████████| 8323/8323 [05:43<00:00, 24.25it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 14:28    INFO  epoch 19 training [time: 343.26s, train loss: 61587.4211]\n",
      "epoch 19 training [time: 343.26s, train loss: 61587.4211]\n",
      "epoch 19 training [time: 343.26s, train loss: 61587.4211]\n",
      "29 Mar 14:28    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    20: 100%|█████████████████████| 8323/8323 [05:45<00:00, 24.09it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 14:34    INFO  epoch 20 training [time: 345.58s, train loss: 61557.8949]\n",
      "epoch 20 training [time: 345.58s, train loss: 61557.8949]\n",
      "epoch 20 training [time: 345.58s, train loss: 61557.8949]\n",
      "29 Mar 14:34    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    21: 100%|█████████████████████| 8323/8323 [05:44<00:00, 24.14it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 14:39    INFO  epoch 21 training [time: 344.76s, train loss: 61534.3443]\n",
      "epoch 21 training [time: 344.76s, train loss: 61534.3443]\n",
      "epoch 21 training [time: 344.76s, train loss: 61534.3443]\n",
      "29 Mar 14:39    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    22: 100%|█████████████████████| 8323/8323 [05:44<00:00, 24.18it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 14:45    INFO  epoch 22 training [time: 344.19s, train loss: 61510.4295]\n",
      "epoch 22 training [time: 344.19s, train loss: 61510.4295]\n",
      "epoch 22 training [time: 344.19s, train loss: 61510.4295]\n",
      "29 Mar 14:45    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    23: 100%|█████████████████████| 8323/8323 [05:45<00:00, 24.09it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 14:51    INFO  epoch 23 training [time: 345.58s, train loss: 61491.4501]\n",
      "epoch 23 training [time: 345.58s, train loss: 61491.4501]\n",
      "epoch 23 training [time: 345.58s, train loss: 61491.4501]\n",
      "29 Mar 14:51    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    24: 100%|█████████████████████| 8323/8323 [05:45<00:00, 24.09it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 14:57    INFO  epoch 24 training [time: 345.51s, train loss: 61472.6081]\n",
      "epoch 24 training [time: 345.51s, train loss: 61472.6081]\n",
      "epoch 24 training [time: 345.51s, train loss: 61472.6081]\n",
      "29 Mar 14:57    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    25: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.33it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 15:02    INFO  epoch 25 training [time: 342.11s, train loss: 61453.2877]\n",
      "epoch 25 training [time: 342.11s, train loss: 61453.2877]\n",
      "epoch 25 training [time: 342.11s, train loss: 61453.2877]\n",
      "29 Mar 15:02    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    26: 100%|█████████████████████| 8323/8323 [05:37<00:00, 24.66it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 15:08    INFO  epoch 26 training [time: 337.47s, train loss: 61438.8641]\n",
      "epoch 26 training [time: 337.47s, train loss: 61438.8641]\n",
      "epoch 26 training [time: 337.47s, train loss: 61438.8641]\n",
      "29 Mar 15:08    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    27: 100%|█████████████████████| 8323/8323 [05:37<00:00, 24.63it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 15:14    INFO  epoch 27 training [time: 337.95s, train loss: 61423.0576]\n",
      "epoch 27 training [time: 337.95s, train loss: 61423.0576]\n",
      "epoch 27 training [time: 337.95s, train loss: 61423.0576]\n",
      "29 Mar 15:14    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    28: 100%|█████████████████████| 8323/8323 [05:37<00:00, 24.64it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 15:19    INFO  epoch 28 training [time: 337.75s, train loss: 61409.7891]\n",
      "epoch 28 training [time: 337.75s, train loss: 61409.7891]\n",
      "epoch 28 training [time: 337.75s, train loss: 61409.7891]\n",
      "29 Mar 15:19    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    29: 100%|█████████████████████| 8323/8323 [05:39<00:00, 24.53it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 15:25    INFO  epoch 29 training [time: 339.28s, train loss: 61397.5963]\n",
      "epoch 29 training [time: 339.28s, train loss: 61397.5963]\n",
      "epoch 29 training [time: 339.28s, train loss: 61397.5963]\n",
      "29 Mar 15:25    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    30: 100%|█████████████████████| 8323/8323 [05:38<00:00, 24.61it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 15:31    INFO  epoch 30 training [time: 338.15s, train loss: 61384.7397]\n",
      "epoch 30 training [time: 338.15s, train loss: 61384.7397]\n",
      "epoch 30 training [time: 338.15s, train loss: 61384.7397]\n",
      "29 Mar 15:31    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    31: 100%|█████████████████████| 8323/8323 [05:38<00:00, 24.58it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 15:36    INFO  epoch 31 training [time: 338.61s, train loss: 61370.4994]\n",
      "epoch 31 training [time: 338.61s, train loss: 61370.4994]\n",
      "epoch 31 training [time: 338.61s, train loss: 61370.4994]\n",
      "29 Mar 15:36    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    32: 100%|█████████████████████| 8323/8323 [05:41<00:00, 24.35it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 15:42    INFO  epoch 32 training [time: 341.80s, train loss: 61362.1523]\n",
      "epoch 32 training [time: 341.80s, train loss: 61362.1523]\n",
      "epoch 32 training [time: 341.80s, train loss: 61362.1523]\n",
      "29 Mar 15:42    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    33: 100%|█████████████████████| 8323/8323 [05:41<00:00, 24.36it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 15:48    INFO  epoch 33 training [time: 341.64s, train loss: 61351.4307]\n",
      "epoch 33 training [time: 341.64s, train loss: 61351.4307]\n",
      "epoch 33 training [time: 341.64s, train loss: 61351.4307]\n",
      "29 Mar 15:48    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    34: 100%|█████████████████████| 8323/8323 [05:41<00:00, 24.36it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 15:53    INFO  epoch 34 training [time: 341.69s, train loss: 61342.7241]\n",
      "epoch 34 training [time: 341.69s, train loss: 61342.7241]\n",
      "epoch 34 training [time: 341.69s, train loss: 61342.7241]\n",
      "29 Mar 15:53    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    35: 100%|█████████████████████| 8323/8323 [05:38<00:00, 24.57it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 15:59    INFO  epoch 35 training [time: 338.76s, train loss: 61332.7208]\n",
      "epoch 35 training [time: 338.76s, train loss: 61332.7208]\n",
      "epoch 35 training [time: 338.76s, train loss: 61332.7208]\n",
      "29 Mar 15:59    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    36: 100%|█████████████████████| 8323/8323 [05:43<00:00, 24.26it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 16:05    INFO  epoch 36 training [time: 343.04s, train loss: 61323.8006]\n",
      "epoch 36 training [time: 343.04s, train loss: 61323.8006]\n",
      "epoch 36 training [time: 343.04s, train loss: 61323.8006]\n",
      "29 Mar 16:05    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    37: 100%|█████████████████████| 8323/8323 [05:45<00:00, 24.06it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 16:10    INFO  epoch 37 training [time: 345.89s, train loss: 61318.2089]\n",
      "epoch 37 training [time: 345.89s, train loss: 61318.2089]\n",
      "epoch 37 training [time: 345.89s, train loss: 61318.2089]\n",
      "29 Mar 16:10    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    38: 100%|█████████████████████| 8323/8323 [05:43<00:00, 24.20it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 16:16    INFO  epoch 38 training [time: 343.90s, train loss: 61311.0800]\n",
      "epoch 38 training [time: 343.90s, train loss: 61311.0800]\n",
      "epoch 38 training [time: 343.90s, train loss: 61311.0800]\n",
      "29 Mar 16:16    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    39: 100%|█████████████████████| 8323/8323 [05:43<00:00, 24.23it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 16:22    INFO  epoch 39 training [time: 343.51s, train loss: 61302.7770]\n",
      "epoch 39 training [time: 343.51s, train loss: 61302.7770]\n",
      "epoch 39 training [time: 343.51s, train loss: 61302.7770]\n",
      "29 Mar 16:22    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    40: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.29it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 16:28    INFO  epoch 40 training [time: 342.74s, train loss: 61296.4852]\n",
      "epoch 40 training [time: 342.74s, train loss: 61296.4852]\n",
      "epoch 40 training [time: 342.74s, train loss: 61296.4852]\n",
      "29 Mar 16:28    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    41: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.28it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 16:33    INFO  epoch 41 training [time: 342.85s, train loss: 61289.8809]\n",
      "epoch 41 training [time: 342.85s, train loss: 61289.8809]\n",
      "epoch 41 training [time: 342.85s, train loss: 61289.8809]\n",
      "29 Mar 16:33    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    42: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.29it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 16:39    INFO  epoch 42 training [time: 342.72s, train loss: 61282.8804]\n",
      "epoch 42 training [time: 342.72s, train loss: 61282.8804]\n",
      "epoch 42 training [time: 342.72s, train loss: 61282.8804]\n",
      "29 Mar 16:39    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    43: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.31it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 16:45    INFO  epoch 43 training [time: 342.36s, train loss: 61278.2187]\n",
      "epoch 43 training [time: 342.36s, train loss: 61278.2187]\n",
      "epoch 43 training [time: 342.36s, train loss: 61278.2187]\n",
      "29 Mar 16:45    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    44: 100%|█████████████████████| 8323/8323 [05:41<00:00, 24.34it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 16:50    INFO  epoch 44 training [time: 341.91s, train loss: 61271.4320]\n",
      "epoch 44 training [time: 341.91s, train loss: 61271.4320]\n",
      "epoch 44 training [time: 341.91s, train loss: 61271.4320]\n",
      "29 Mar 16:50    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    45: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.27it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 16:56    INFO  epoch 45 training [time: 342.93s, train loss: 61267.7216]\n",
      "epoch 45 training [time: 342.93s, train loss: 61267.7216]\n",
      "epoch 45 training [time: 342.93s, train loss: 61267.7216]\n",
      "29 Mar 16:56    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    46: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.30it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 17:02    INFO  epoch 46 training [time: 342.56s, train loss: 61262.3848]\n",
      "epoch 46 training [time: 342.56s, train loss: 61262.3848]\n",
      "epoch 46 training [time: 342.56s, train loss: 61262.3848]\n",
      "29 Mar 17:02    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    47: 100%|█████████████████████| 8323/8323 [05:42<00:00, 24.30it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 17:08    INFO  epoch 47 training [time: 342.58s, train loss: 61258.2511]\n",
      "epoch 47 training [time: 342.58s, train loss: 61258.2511]\n",
      "epoch 47 training [time: 342.58s, train loss: 61258.2511]\n",
      "29 Mar 17:08    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    48: 100%|█████████████████████| 8323/8323 [05:40<00:00, 24.42it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 17:13    INFO  epoch 48 training [time: 340.82s, train loss: 61252.0007]\n",
      "epoch 48 training [time: 340.82s, train loss: 61252.0007]\n",
      "epoch 48 training [time: 340.82s, train loss: 61252.0007]\n",
      "29 Mar 17:13    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Train    49: 100%|█████████████████████| 8323/8323 [05:43<00:00, 24.21it/s, GPU RAM: 2.20 G/15.78 G]\n",
      "29 Mar 17:19    INFO  epoch 49 training [time: 343.75s, train loss: 61248.0692]\n",
      "epoch 49 training [time: 343.75s, train loss: 61248.0692]\n",
      "epoch 49 training [time: 343.75s, train loss: 61248.0692]\n",
      "29 Mar 17:19    INFO  Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n",
      "Saving current: saved/GRU4Rec-Mar-29-2022_12-34-37.pth\n"
     ]
    }
   ],
   "source": [
    "best_valid_score, best_valid_result = trainer.fit(train_data, valid_data=valid_data, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXOGR2_Ua7it"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "gru4rec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
